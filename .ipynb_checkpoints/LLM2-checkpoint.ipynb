{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d059546c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick Recap\n",
    "- Talked about onboarding to GCP and some high-level contents w.r.t. how LLMs work\n",
    "- In particular touch upon the following concept:\n",
    "    - Temperature\n",
    "    - top_N\n",
    "    - probabilities \n",
    "- Now switching gear back to the learning series, we will talk about Application of LLMs today.\n",
    "- Let's begin with the five common pillars recognized by OpenAI (or GPT-4 itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84ce98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key Applications Recognized\n",
    "1. Content Creation\n",
    "    - write articles\n",
    "    - generate ideas/scripts for writers\n",
    "    - **creativity and fluency**\n",
    "2. Conversation Agents:\n",
    "    - chatbot/virtual assistant (Pershin X)\n",
    "    - Human-like **interaction**\n",
    "    - _Can answer queries, provide recommendations and hold conversations_\n",
    "3. Translation:\n",
    "    - not explicitly trained to do this\n",
    "    - _Can handle various languages nonetheless_\n",
    "4. Education\n",
    "    - Tutor various subjects\n",
    "    - _Can provide explanations, stimulate creative thinking_\n",
    "5. Programming Help: CoPilot\n",
    "    - _Can generate code snippets and assist with debugging_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efdd03",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Limitations and Ethical Considerations of Large Language Models\n",
    "- Limitations\n",
    "    - Understanding vs. Pattern Matching\n",
    "    - Sensitivity to Input Phrasing\n",
    "    - Verifiability of information: generating plausible-sounding but incorrect/nonsensical information.\n",
    "        - no inherent way to verify accuracy of the information it generates\n",
    "        - __but doesn't 'grounding' solve this?__\n",
    "- Ethical Considerations\n",
    "    - Bias in Training Data\n",
    "        - gender, racial cultral biases and more\n",
    "    - Misuse of Technology\n",
    "        - deepfake text for nefarious purposes\n",
    "    - Social/Environmental Impact\n",
    "        - training of LLM is very energy intensive ad requires significant amount of computational resources\n",
    "        - Role of human/smart copiers' role in RLHF\n",
    "3. Translation:\n",
    "    - not explicitly trained to do this\n",
    "    - _Can handle various languages nonetheless_\n",
    "4. Education\n",
    "    - Tutor various subjects\n",
    "    - _Can provide explanations, stimulate creative thinking_\n",
    "5. Programming Help: CoPilot\n",
    "    - _Can generate code snippets and assist with debugging_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed74f42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How does 'Grounding' work?\n",
    "- What is 'grounding':\n",
    "    - Refers to the concept of connecting the LLM with real-world concrete data or knowledge source\n",
    "    - May include:\n",
    "        - linking to specific databases, \n",
    "        - using factual knowledge graphs, or \n",
    "        - providing the model with access to up-to-date information on the internet.\n",
    "- MSFT once claimed it will resolve most of our concerns/problems.\n",
    "    - RFP PoC/Pilot\n",
    "    - Chat with your PDF(s) demo \n",
    "- **Verfiability issue is more than just factual grounding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17836f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why doesn't 'Grounding' work?\n",
    "- Grouding will improve accuracy of responses and keep them factual\n",
    "- Creates a form of question-answering system that performs semantic search over a known corpus of documents\n",
    "- Some points to consider:\n",
    "    1. Model interpretation (temp=0, aka model outputs more deterministic): model understanding â‰  human understanding;\n",
    "    2. Accuracy within context: errors acn arise from:\n",
    "        - biases/inaccuracies in training data, \n",
    "        - misinterpretation of context, \n",
    "        - limitations in the model's understanding of complex language structures;\n",
    "    3. Handling Ambiguity: question or context is ambigous, the model might struggle to provide an accurate and relevant answer.\n",
    "\n",
    "### **'Grounding' may improve verifiability of a model's response, it won't eliminate the issue.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ad034",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why doesn't Grounding work? An example from RFP.\n",
    "- What is your headquarter?\n",
    "    - Not typically how someone would ask for the location of a headquarters. \n",
    "    - might be asking:\n",
    "        - about the function or nature of the headquarters, or\n",
    "        - might be a misphrased question asking for the location\n",
    "    - more semantically ambiguous, less clear what kind of answer is expected\n",
    "- Where is your headquarter?\n",
    "    - standard way of asking for the location of a headquarters\n",
    "    -  ambiguity here lies primarily in the referent of \"your\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe86044",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mitigating LLM Risks\n",
    "- Fine-tuning on specific datasets: improve behavior for **specific** applications\n",
    "    - Refers to the concept of connecting the LLM with real-world concrete data or knowledge source\n",
    "    - May include:\n",
    "        - linking to specific databases, \n",
    "        - using factual knowledge graphs, or \n",
    "        - providing the model with access to up-to-date information on the internet.\n",
    "- MSFT once claimed it will resolve most of our concerns/problems.\n",
    "    - RFP PoC/Pilot\n",
    "    - Chat with your PDF(s) demo \n",
    "- **Verfiability issue is more than just factual grounding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc40681",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick Re-Cap on what we discussed\n",
    "- Basics of LLMs\n",
    "    - What they are and how they are trained\n",
    "- Architecture of GPT models (Decoder-only ones started by OpenAI)\n",
    "    - Transformer architecture\n",
    "    - Decoder-only vs. encoder-decoder architectures\n",
    "- Implementation and Deployment\n",
    "    - APIs\n",
    "    - Real-world usage and applications we built\n",
    "- Limitations and Concerns\n",
    "    - Lack of human-intent-understanding capability\n",
    "    - Inability to provide verification\n",
    "    - Proneness to biases\n",
    "- Implications of LLMs\n",
    "    - Wide-ranging capabilities and applications of these models\n",
    "    - Potential risks and concerns\n",
    "    - Strategies to mitigate these risks"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
