<!DOCTYPE html>
<html>
    <head>
        <title>Web-Scraping 101</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="bear-note-unique-identifier" content="6F838B51-E23A-466B-9501-C46CE0898DF7-62100-00001C644FB997AB">
        <meta name="created" content="2023-10-16T11:51:55+0800"/>
        <meta name="modified" content="2023-10-16T12:23:44+0800"/>
        <meta name="tags" content=""/>
        <meta name="last device" content="Hongshan’s Laptop"/>
    </head>
    <body>
        <div class="note-wrapper">
            <h1 id="Web-Scraping 101">Web-Scraping 101</h1>
<p>Note that any activity that scrapes or collects data from online platforms should strictly adhere to the respective platform's terms of service, API usage guidelines, and any relevant laws or regulations.</p>
<p><i>Don’t hardcode your credentials</i></p>
<br>
<h2 id="Social Media Information:">Social Media Information:</h2>
<ol start="1"><li><b>Use Official APIs</b>:
</li></ol>
<ul><li>    Many social media platforms, like Twitter, Facebook, and Instagram, offer Application Programming Interfaces (APIs). These allow developers to retrieve data in a structured manner. For instance, Twitter's API can be accessed using libraries like Tweepy in Python.
</li><li>    <b>Pros</b>: Structured, reliable, and typically includes metadata.
</li><li>    <b>Cons</b>: Often rate-limited, requires API keys, may have costs associated, and might not provide access to all data.
</li></ul>
<br>
<ol start="2"><li><b>Web Scraping</b>:
</li></ol>
<ul><li>    Tools like Scrapy, Beautiful Soup (for Python), or Puppeteer (for JavaScript) can be used to scrape social media pages. This method involves downloading the webpage content and extracting the desired information.
</li><li>    <b>Pros</b>: Can potentially retrieve more data than allowed by APIs.
</li><li>    <b>Cons</b>: Fragile (can break if the website structure changes), might violate terms of service, and can be resource-intensive.
</li></ul>
<br>
<ol start="3"><li><b>Third-party Data Providers</b>:
</li></ol>
<ul><li>    There are services and platforms that collate and provide social media data for research or business purposes. These platforms often have arrangements with social media networks or employ large-scale scraping to collect data.
</li><li>    <b>Pros</b>: Ready-to-use datasets, often extensive and comprehensive.
</li><li>    <b>Cons</b>: Can be expensive, might not be up-to-date, and depends on third-party terms and conditions.
</li></ul>
<br>
<h2 id="News Information:">News Information:</h2>
<ol start="1"><li><b>News APIs</b>:
</li></ol>
<ul><li>    Various news agencies and aggregators offer APIs that allow users to fetch the latest news, headlines, and articles. Examples include the NewsAPI, Event Registry, or the GDELT Project.
</li><li>    <b>Pros</b>: Structured data, real-time or near real-time access, includes metadata.
</li><li>    <b>Cons</b>: May be rate-limited, requires API keys, might have costs associated.
</li></ul>
<br>
<ol start="2"><li><b>Web Scraping</b>(applies to general websites as well):
</li></ol>
<ul><li>    As with social media, news websites can be scraped using tools like Scrapy, Beautiful Soup, or Puppeteer. Additionally, RSS feeds can be an excellent source for news articles and updates.
</li><li>    <b>Pros</b>: Customizable, can retrieve news from sources that don't offer APIs.
</li><li>    <b>Cons</b>: Might violate terms of service, can be fragile and resource-intensive, potential ethical considerations.
</li></ul>
<br>
<ol start="3"><li><b>Pre-curated Datasets</b>:
</li></ol>
<ul><li>    There are repositories and datasets available online that consist of news articles and metadata. Examples include the <i>Kaggle</i> platform or academic datasets.
</li><li>    <b>Pros</b>: Ready-to-use, extensive datasets, often labeled or categorized.
</li><li>    <b>Cons</b>: Might not be current, data might not cover recent events, depends on third-party terms and conditions.
</li></ul>
<br>
<p>Practice ethics, legality, and terms of service. Always encourage students to respect these considerations and obtain permissions where required.</p>
<hr>
<h2 id="Twitter Scraping Example">Twitter Scraping Example</h2>
<p>Certainly! Let's start by demonstrating how to fetch tweets using the Tweepy library and Twitter's official API.</p>
<br>
<h4 id="Prerequisites:">Prerequisites:</h4>
<ol start="1"><li>Install tweepy:
</li></ol>
<pre><code class='code-multiline'>pip install tweepy</code></pre>
<p><br></p>
<ol start="2"><li>Obtain API credentials from the Twitter Developer platform:
</li></ol>
<ul><li>   Create an application at <a href="https://developer.twitter.com/">Twitter Developer Console</a>.
</li><li>   Once the application is created, you'll get:
<ul><li>     API Key
</li><li>     API Secret Key
</li><li>     Access Token
</li><li>     Access Token Secret
</li></ul>
</li></ul>
<br>
<h4 id="Example Code:">Example Code:</h4>
<br>
<pre><code class='code-multiline' lang='python'><span class="sf_code_keyword">import</span> tweepy

<span class="sf_code_comment"># Twitter API Credentials</span>
API_KEY <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_API_KEY'</span>
API_SECRET_KEY <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_API_SECRET_KEY'</span>
ACCESS_TOKEN <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_ACCESS_TOKEN'</span>
ACCESS_TOKEN_SECRET <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_ACCESS_TOKEN_SECRET'</span>

<span class="sf_code_comment"># Authenticate with Tweepy</span>
auth <span class="sf_code_operator">=</span> tweepy<span class="sf_code_punctuation">.</span>OAuth1UserHandler<span class="sf_code_punctuation">(</span>
    consumer_key<span class="sf_code_operator">=</span>API_KEY<span class="sf_code_punctuation">,</span>
    consumer_secret<span class="sf_code_operator">=</span>API_SECRET_KEY<span class="sf_code_punctuation">,</span>
    access_token<span class="sf_code_operator">=</span>ACCESS_TOKEN<span class="sf_code_punctuation">,</span>
    access_token_secret<span class="sf_code_operator">=</span>ACCESS_TOKEN_SECRET
<span class="sf_code_punctuation">)</span>

api <span class="sf_code_operator">=</span> tweepy<span class="sf_code_punctuation">.</span>API<span class="sf_code_punctuation">(</span>auth<span class="sf_code_punctuation">)</span>

<span class="sf_code_comment"># Fetch recent tweets from a specific user</span>
user_name <span class="sf_code_operator">=</span> <span class="sf_code_string">'twitter_handle'</span>  <span class="sf_code_comment"># e.g., 'elonmusk'</span>
tweets <span class="sf_code_operator">=</span> api<span class="sf_code_punctuation">.</span>user_timeline<span class="sf_code_punctuation">(</span>screen_name<span class="sf_code_operator">=</span>user_name<span class="sf_code_punctuation">,</span> count<span class="sf_code_operator">=</span><span class="sf_code_number">10</span><span class="sf_code_punctuation">)</span>  <span class="sf_code_comment"># Fetches the 10 most recent tweets</span>

<span class="sf_code_keyword">for</span> tweet <span class="sf_code_keyword">in</span> tweets<span class="sf_code_punctuation">:</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>tweet<span class="sf_code_punctuation">.</span>text<span class="sf_code_punctuation">)</span>  <span class="sf_code_comment"># Print the content of each tweet</span>

<span class="sf_code_comment"># If you want to search tweets based on a keyword:</span>
query <span class="sf_code_operator">=</span> <span class="sf_code_string">'machine learning'</span>
<span class="sf_code_keyword">for</span> tweet <span class="sf_code_keyword">in</span> tweepy<span class="sf_code_punctuation">.</span>Cursor<span class="sf_code_punctuation">(</span>api<span class="sf_code_punctuation">.</span>search<span class="sf_code_punctuation">,</span> q<span class="sf_code_operator">=</span>query<span class="sf_code_punctuation">,</span> lang<span class="sf_code_operator">=</span><span class="sf_code_string">"en"</span><span class="sf_code_punctuation">).</span>items<span class="sf_code_punctuation">(</span><span class="sf_code_number">10</span><span class="sf_code_punctuation">):</span>  <span class="sf_code_comment"># Fetches 10 tweets with the keyword</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>tweet<span class="sf_code_punctuation">.</span>text<span class="sf_code_punctuation">)</span></code></pre>
<p><br></p>
<hr>
<h2 id="Reddit Scraping Example">Reddit Scraping Example</h2>
<p>Certainly! Reddit's official API is another excellent resource for gathering data. The Python library <code class='code-inline'>PRAW</code> (Python Reddit API Wrapper) provides a friendly interface to interact with Reddit's API.</p>
<br>
<h4 id="Prerequisites:">Prerequisites:</h4>
<ol start="1"><li>Install PRAW:
</li></ol>
<pre><code class='code-multiline'>pip install praw</code></pre>
<p><br></p>
<ol start="2"><li>Set up a Reddit App:
</li></ol>
<ul><li>   Log in to your Reddit account and navigate to: <a href="https://www.reddit.com/prefs/apps">Reddit App Preferences</a>
</li><li>   Click "Create App" or "Create Another App".
</li><li>   Fill out the required fields: name, App type (choose script for personal use), description (can be left blank), permissions, etc.
</li><li>   After creating the app, you will have:
<ul><li>     <code class='code-inline'>client_id</code> (right below the app name)
</li><li>     <code class='code-inline'>client_secret</code>
</li></ul>
</li></ul>
<br>
<h4 id="Example Code:">Example Code:</h4>
<br>
<pre><code class='code-multiline' lang='python'><span class="sf_code_keyword">import</span> praw

<span class="sf_code_comment"># Reddit App Credentials</span>
CLIENT_ID <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_CLIENT_ID'</span>
CLIENT_SECRET <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_CLIENT_SECRET'</span>
USER_AGENT <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_APP_NAME by /u/YOUR_REDDIT_USERNAME'</span>

<span class="sf_code_comment"># Authenticate with PRAW</span>
reddit <span class="sf_code_operator">=</span> praw<span class="sf_code_punctuation">.</span>Reddit<span class="sf_code_punctuation">(</span>
    client_id<span class="sf_code_operator">=</span>CLIENT_ID<span class="sf_code_punctuation">,</span>
    client_secret<span class="sf_code_operator">=</span>CLIENT_SECRET<span class="sf_code_punctuation">,</span>
    user_agent<span class="sf_code_operator">=</span>USER_AGENT
<span class="sf_code_punctuation">)</span>

<span class="sf_code_comment"># Fetch top 10 posts from a specific subreddit</span>
subreddit_name <span class="sf_code_operator">=</span> <span class="sf_code_string">'MachineLearning'</span>
subreddit <span class="sf_code_operator">=</span> reddit<span class="sf_code_punctuation">.</span>subreddit<span class="sf_code_punctuation">(</span>subreddit_name<span class="sf_code_punctuation">)</span>

<span class="sf_code_keyword">for</span> post <span class="sf_code_keyword">in</span> subreddit<span class="sf_code_punctuation">.</span>top<span class="sf_code_punctuation">(</span>limit<span class="sf_code_operator">=</span><span class="sf_code_number">10</span><span class="sf_code_punctuation">):</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>post<span class="sf_code_punctuation">.</span>title<span class="sf_code_punctuation">)</span>  <span class="sf_code_comment"># Print the title of each post</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>post<span class="sf_code_punctuation">.</span>url<span class="sf_code_punctuation">)</span>    <span class="sf_code_comment"># Print the URL of each post</span>

<span class="sf_code_comment"># Search for posts containing a specific keyword across all of Reddit</span>
query <span class="sf_code_operator">=</span> <span class="sf_code_string">'artificial intelligence'</span>
<span class="sf_code_keyword">for</span> post <span class="sf_code_keyword">in</span> reddit<span class="sf_code_punctuation">.</span>subreddit<span class="sf_code_punctuation">(</span><span class="sf_code_string">'all'</span><span class="sf_code_punctuation">).</span>search<span class="sf_code_punctuation">(</span>query<span class="sf_code_punctuation">,</span> limit<span class="sf_code_operator">=</span><span class="sf_code_number">10</span><span class="sf_code_punctuation">):</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>post<span class="sf_code_punctuation">.</span>title<span class="sf_code_punctuation">)</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>post<span class="sf_code_punctuation">.</span>url<span class="sf_code_punctuation">)</span></code></pre>
<p><br></p>
<p>Note Reddit's API has rate limits. <code class='code-inline'>PRAW</code> respects these limits and will wait accordingly before making more requests if you hit them.</p>
<hr>
<h2 id="News (NYT) Scraping Example">News (NYT) Scraping Example</h2>
<p>Many major news platforms provide their APIs to allow developers to access and distribute their content. Below are some well-known news services that offer APIs:</p>
<br>
<ol start="1"><li><b>The New York Times (NYT)</b>: The NYT provides several APIs that give access to different types of news data, from articles to movie reviews.
</li></ol>
<p>   </p>
<ol start="2"><li><b>BBC</b>: While the BBC doesn't have a public API for all of its news content, they do offer an RSS feed which can be parsed and used similarly to an API for many purposes.
</li></ol>
<br>
<ol start="3"><li><b>Currents API</b>: Offers the latest news published in various blogs, news websites, magazines, and newspapers.
</li></ol>
<br>
<ol start="4"><li><b>Event Registry</b>: Collects news articles from numerous sources globally and offers an API to search and analyze them.
</li></ol>
<br>
<ol start="5"><li><b>Guardian</b>: The Guardian offers an open platform that allows access to their articles, images, podcasts, and videos.
</li></ol>
<br>
<ol start="6"><li><b>Bing News Search</b>: Part of Microsoft's Cognitive Services, Bing News Search provides an API to search the web for news articles.
</li></ol>
<br>
<p>Let's proceed with an example for <b>The New York Times (NYT)</b>, one of the most reputable news sources with a comprehensive API:</p>
<br>
<h2 id="The New York Times API:">The New York Times API:</h2>
<br>
<h4 id="Prerequisites:">Prerequisites:</h4>
<ol start="1"><li>Register on <a href="https://developer.nytimes.com/">The New York Times Developer Portal</a>.
</li><li>Create a new App to access the "Article Search API".
</li><li>Get your API key for the App.
</li></ol>
<br>
<h4 id="Example Code:">Example Code:</h4>
<br>
<pre><code class='code-multiline' lang='python'><span class="sf_code_keyword">import</span> requests

<span class="sf_code_comment"># NYT API Key</span>
API_KEY <span class="sf_code_operator">=</span> <span class="sf_code_string">'YOUR_NYT_API_KEY'</span>

<span class="sf_code_comment"># Base URL for Article Search API</span>
BASE_URL <span class="sf_code_operator">=</span> <span class="sf_code_string">"https://api.nytimes.com/svc/search/v2/articlesearch.json"</span>

<span class="sf_code_comment"># Parameters for the request</span>
params <span class="sf_code_operator">=</span> <span class="sf_code_punctuation">{</span>
    <span class="sf_code_string">'q'</span><span class="sf_code_punctuation">:</span> <span class="sf_code_string">'technology'</span><span class="sf_code_punctuation">,</span>  <span class="sf_code_comment"># Search term</span>
    <span class="sf_code_string">'api-key'</span><span class="sf_code_punctuation">:</span> API_KEY<span class="sf_code_punctuation">,</span>
    <span class="sf_code_string">'page'</span><span class="sf_code_punctuation">:</span> <span class="sf_code_number">0</span>  <span class="sf_code_comment"># Fetch the first page of results</span>
<span class="sf_code_punctuation">}</span>

response <span class="sf_code_operator">=</span> requests<span class="sf_code_punctuation">.</span>get<span class="sf_code_punctuation">(</span>BASE_URL<span class="sf_code_punctuation">,</span> params<span class="sf_code_operator">=</span>params<span class="sf_code_punctuation">)</span>

<span class="sf_code_comment"># Check if the request was successful</span>
<span class="sf_code_keyword">if</span> response<span class="sf_code_punctuation">.</span>status_code <span class="sf_code_operator">==</span> <span class="sf_code_number">200</span><span class="sf_code_punctuation">:</span>
    docs <span class="sf_code_operator">=</span> response<span class="sf_code_punctuation">.</span>json<span class="sf_code_punctuation">().</span>get<span class="sf_code_punctuation">(</span><span class="sf_code_string">'response'</span><span class="sf_code_punctuation">).</span>get<span class="sf_code_punctuation">(</span><span class="sf_code_string">'docs'</span><span class="sf_code_punctuation">)</span>
    <span class="sf_code_keyword">for</span> doc <span class="sf_code_keyword">in</span> docs<span class="sf_code_punctuation">:</span>
        <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>doc<span class="sf_code_punctuation">[</span><span class="sf_code_string">'headline'</span><span class="sf_code_punctuation">][</span><span class="sf_code_string">'main'</span><span class="sf_code_punctuation">])</span>  <span class="sf_code_comment"># Print the headline of the article</span>
        <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>doc<span class="sf_code_punctuation">[</span><span class="sf_code_string">'web_url'</span><span class="sf_code_punctuation">])</span>           <span class="sf_code_comment"># Print the URL of the article</span>
<span class="sf_code_keyword">else</span><span class="sf_code_punctuation">:</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>f<span class="sf_code_string">"Error {response.status_code}: Unable to fetch data from The New York Times API"</span><span class="sf_code_punctuation">)</span></code></pre>
<p><br></p>
<p>Always ensure you're following the terms of use for each API. Most news platforms impose limits on the number of requests, the volume of data retrieved, and how that data can be displayed or redistributed.</p>
<hr>
<h2 id="RSS Feed Scraping Example">RSS Feed Scraping Example</h2>
<p>RSS (Really Simple Syndication) feeds are a great way to fetch news updates from websites without having to resort to web scraping. They provide data in a structured XML format, which can be easily parsed to extract relevant information.</p>
<br>
<p>Here's a simple example using Python to fetch and parse an RSS feed. We'll use the <code class='code-inline'>feedparser</code> library, which simplifies the process.</p>
<br>
<h4 id="Prerequisites:">Prerequisites:</h4>
<ol start="1"><li>Install the required library:
</li></ol>
<pre><code class='code-multiline'>pip install feedparser</code></pre>
<p><br></p>
<h4 id="Example Code:">Example Code:</h4>
<br>
<pre><code class='code-multiline' lang='python'><span class="sf_code_keyword">import</span> feedparser

<span class="sf_code_comment"># URL of the RSS feed</span>
RSS_FEED_URL <span class="sf_code_operator">=</span> <span class="sf_code_string">'https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml'</span>  <span class="sf_code_comment"># For instance, The New York Times homepage feed</span>

<span class="sf_code_comment"># Parse the RSS feed</span>
feed <span class="sf_code_operator">=</span> feedparser<span class="sf_code_punctuation">.</span>parse<span class="sf_code_punctuation">(</span>RSS_FEED_URL<span class="sf_code_punctuation">)</span>

<span class="sf_code_comment"># Loop through each entry/item in the feed</span>
<span class="sf_code_keyword">for</span> entry <span class="sf_code_keyword">in</span> feed<span class="sf_code_punctuation">.</span>entries<span class="sf_code_punctuation">:</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>entry<span class="sf_code_punctuation">.</span>title<span class="sf_code_punctuation">)</span>       <span class="sf_code_comment"># Print the title of the article</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>entry<span class="sf_code_punctuation">.</span>link<span class="sf_code_punctuation">)</span>        <span class="sf_code_comment"># Print the URL/link of the article</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>entry<span class="sf_code_punctuation">.</span>description<span class="sf_code_punctuation">)</span> <span class="sf_code_comment"># Print the description or summary of the article</span>
    <span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span><span class="sf_code_string">'---------------------'</span><span class="sf_code_punctuation">)</span>

<span class="sf_code_comment"># If you're interested in the feed metadata (like feed title, feed link, etc.):</span>
<span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>feed<span class="sf_code_punctuation">.</span>feed<span class="sf_code_punctuation">.</span>title<span class="sf_code_punctuation">)</span>       <span class="sf_code_comment"># Print the title of the feed (e.g., "NYT &gt; Top Stories")</span>
<span class="sf_code_keyword">print</span><span class="sf_code_punctuation">(</span>feed<span class="sf_code_punctuation">.</span>feed<span class="sf_code_punctuation">.</span>link<span class="sf_code_punctuation">)</span>        <span class="sf_code_comment"># Print the link of the feed</span></code></pre>
<p><br></p>
<p>You can easily adapt the above code to work with other news websites or blogs by changing the <code class='code-inline'>RSS_FEED_URL</code> to point to the desired RSS feed. Keep in mind that while RSS feeds provide a structured way to access content, they might not contain the full content of the articles or all the details you might find on the actual website. They usually contain titles, summaries, and links to the full articles.</p>

        </div>
        <script type="text/javascript">
            (function() {

    var doc_ols = document.getElementsByTagName("ol");

    for ( i=0; i<doc_ols.length; i++) {

        var ol_start = doc_ols[i].getAttribute("start") - 1;
        doc_ols[i].setAttribute("style", "counter-reset:ol_counter " + ol_start + ";");

    }

})();

        </script>
        <style>
            html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td,article,aside,canvas,details,embed,figure,figcaption,footer,header,hgroup,menu,nav,output,ruby,section,summary,time,mark,audio,video{margin:0;padding:0;border:0;font:inherit;font-size:100%;vertical-align:baseline}html{line-height:1}ol,ul{list-style:none}table{border-collapse:collapse;border-spacing:0}caption,th,td{text-align:left;font-weight:normal;vertical-align:middle}q,blockquote{quotes:none}q:before,q:after,blockquote:before,blockquote:after{content:"";content:none}a img{border:none}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}*{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}html{font-size:87.5%;line-height:1.57143em}html{font-size:14px;line-height:1.6em;-webkit-text-size-adjust:100%}body{background:#fcfcfc;color:#545454;text-rendering:optimizeLegibility;font-family:"AvenirNext-Regular"}a{color:#de4c4f;text-decoration:none}h1{font-family:"AvenirNext-Medium";color:#333;font-size:1.6em;line-height:1.3em;margin-bottom:.78571em}h2{font-family:"AvenirNext-Medium";color:#333;font-size:1.3em;line-height:1em;margin-bottom:.62857em}h3{font-family:"AvenirNext-Medium";color:#333;font-size:1.15em;line-height:1em;margin-bottom:.47143em}p{margin-bottom:1.57143em;hyphens:auto}hr{height:1px;border:0;background-color:#dedede;margin:-1px auto 1.57143em auto}ul,ol{margin-bottom:.31429em}ul ul,ul ol,ol ul,ol ol{margin-bottom:0px}ol{counter-reset:ol_counter}ol li:before{content:counter(ol_counter) ".";counter-increment:ol_counter;color:#e06e73;text-align:right;display:inline-block;min-width:1em;margin-right:0.5em}b,strong{font-family:"AvenirNext-Bold"}i,em{font-family:"AvenirNext-Italic"}code{font-family:"Menlo-Regular"}.text-overflow-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.sf_code_string,.sf_code_selector,.sf_code_attr-name,.sf_code_char,.sf_code_builtin,.sf_code_inserted{color:#D33905}.sf_code_comment,.sf_code_prolog,.sf_code_doctype,.sf_code_cdata{color:#838383}.sf_code_number,.sf_code_boolean{color:#0E73A2}.sf_code_keyword,.sf_code_atrule,.sf_code_rule,.sf_code_attr-value,.sf_code_function,.sf_code_class-name,.sf_code_class,.sf_code_regex,.sf_code_important,.sf_code_variable,.sf_code_interpolation{color:#0E73A2}.sf_code_property,.sf_code_tag,.sf_code_constant,.sf_code_symbol,.sf_code_deleted{color:#1B00CE}.sf_code_macro,.sf_code_entity,.sf_code_operator,.sf_code_url{color:#920448}.note-wrapper{max-width:46em;margin:0px auto;padding:1.57143em 3.14286em}.note-wrapper.spotlight-preview{overflow-x:hidden}u{text-decoration:none;background-image:linear-gradient(to bottom, rgba(0,0,0,0) 50%,#e06e73 50%);background-repeat:repeat-x;background-size:2px 2px;background-position:0 1.05em}s{color:#878787}p{margin-bottom:0.1em}hr{margin-bottom:0.7em;margin-top:0.7em}ul li{text-indent:-0.35em}ul li:before{content:"•";color:#e06e73;display:inline-block;margin-right:0.3em}ul ul{margin-left:1.25714em}ol li{text-indent:-1.45em}ol ol{margin-left:1.25714em}blockquote{display:block;margin-left:-1em;padding-left:0.8em;border-left:0.2em solid #e06e73}.todo-list ul{margin-left:1.88571em}.todo-list li{text-indent:-1.75em}.todo-list li:before{content:"";display:static;margin-right:0px}.todo-checkbox{text-indent:-1.7em}.todo-checkbox svg{margin-right:0.3em;position:relative;top:0.2em}.todo-checkbox svg #check{display:none}.todo-checkbox.todo-checked #check{display:inline}.todo-checkbox.todo-checked+.todo-text{text-decoration:line-through;color:#878787}.code-inline{display:inline;background:white;border:solid 1px #dedede;padding:0.2em 0.5em;font-size:0.9em}.code-multiline{display:block;background:white;border:solid 1px #dedede;padding:0.7em 1em;font-size:0.9em;overflow-x:auto}.hashtag{display:inline-block;color:white;background:#b8bfc2;padding:0.0em 0.5em;border-radius:1em;text-indent:0}.hashtag a{color:#fff}.address a{color:#545454;background-image:linear-gradient(to bottom, rgba(0,0,0,0) 50%,#0da35e 50%);background-repeat:repeat-x;background-size:2px 2px;background-position:0 1.05em}.address svg{position:relative;top:0.2em;display:inline-block;margin-right:0.2em}.color-preview{display:inline-block;width:1em;height:1em;border:solid 1px rgba(0,0,0,0.3);border-radius:50%;margin-right:0.1em;position:relative;top:0.2em;white-space:nowrap}.color-code{margin-right:0.2em;font-family:"Menlo-Regular";font-size:0.9em}.color-hash{opacity:0.4}.ordered-list-number{color:#e06e73;text-align:right;display:inline-block;min-width:1em}.arrow svg{position:relative;top:0.08em;display:inline-block;margin-right:0.15em;margin-left:0.15em}.arrow svg #rod{stroke:#545454}.arrow svg #point{fill:#545454}mark{color:inherit;display:inline;padding:0.2em 0.5em;background-color:#fcffc0}img{max-width:100%;height:auto}

        </style>
    </body>
</html>
