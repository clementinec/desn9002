<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DESN9002 - DESN9002: Sustainable Leadership</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">DESN9002</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../L1.html"> 
<span class="menu-text">Lecture 1: Who Are We, Course Overview, and Introduction to SDGs</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#desn9002-sustainable-leadership" id="toc-desn9002-sustainable-leadership" class="nav-link active" data-scroll-target="#desn9002-sustainable-leadership">DESN9002: Sustainable Leadership</a></li>
  <li><a href="#what-do-you-already-know-about-llmschatgpt" id="toc-what-do-you-already-know-about-llmschatgpt" class="nav-link" data-scroll-target="#what-do-you-already-know-about-llmschatgpt">What do you already know about LLMs/chatGPT?</a>
  <ul class="collapse">
  <li><a href="#prerequisite" id="toc-prerequisite" class="nav-link" data-scroll-target="#prerequisite">PreRequisite</a></li>
  <li><a href="#lecture-overview" id="toc-lecture-overview" class="nav-link" data-scroll-target="#lecture-overview">Lecture Overview</a></li>
  <li><a href="#introduction-to-llms-and-how-they-are-trained" id="toc-introduction-to-llms-and-how-they-are-trained" class="nav-link" data-scroll-target="#introduction-to-llms-and-how-they-are-trained">Introduction to LLMs and how they are trained</a></li>
  <li><a href="#lets-see-some-llms-in-action" id="toc-lets-see-some-llms-in-action" class="nav-link" data-scroll-target="#lets-see-some-llms-in-action">Let’s see some LLMs in action</a></li>
  <li><a href="#architecture-of-llm" id="toc-architecture-of-llm" class="nav-link" data-scroll-target="#architecture-of-llm">Architecture of LLM</a></li>
  <li><a href="#architecture-of-llm---transformer-layer-types" id="toc-architecture-of-llm---transformer-layer-types" class="nav-link" data-scroll-target="#architecture-of-llm---transformer-layer-types">Architecture of LLM - Transformer Layer Types</a></li>
  <li><a href="#architecture-of-llm---data-handling-by-gpt-models" id="toc-architecture-of-llm---data-handling-by-gpt-models" class="nav-link" data-scroll-target="#architecture-of-llm---data-handling-by-gpt-models">Architecture of LLM - Data Handling by GPT Models</a></li>
  <li><a href="#architecture-of-llm---implementation-and-deployment-of-gpt" id="toc-architecture-of-llm---implementation-and-deployment-of-gpt" class="nav-link" data-scroll-target="#architecture-of-llm---implementation-and-deployment-of-gpt">Architecture of LLM - Implementation and deployment of GPT</a></li>
  <li><a href="#architecture-of-llm---back-to-the-sota-models" id="toc-architecture-of-llm---back-to-the-sota-models" class="nav-link" data-scroll-target="#architecture-of-llm---back-to-the-sota-models">Architecture of LLM - Back to the SOTA models</a></li>
  <li><a href="#architecture-of-llm---generative-pre-trained-transformer-aka-openais-proposal" id="toc-architecture-of-llm---generative-pre-trained-transformer-aka-openais-proposal" class="nav-link" data-scroll-target="#architecture-of-llm---generative-pre-trained-transformer-aka-openais-proposal">Architecture of LLM - Generative Pre-trained Transformer aka OpenAI’s proposal</a></li>
  <li><a href="#applications-of-llms-examine-real-world-applications-of-llms-within-various-use-cases." id="toc-applications-of-llms-examine-real-world-applications-of-llms-within-various-use-cases." class="nav-link" data-scroll-target="#applications-of-llms-examine-real-world-applications-of-llms-within-various-use-cases.">Applications of LLMs: Examine real-world applications of LLMs within various use cases.</a></li>
  <li><a href="#common-selection-strategies-seen-in-llm-application-development" id="toc-common-selection-strategies-seen-in-llm-application-development" class="nav-link" data-scroll-target="#common-selection-strategies-seen-in-llm-application-development">Common Selection Strategies seen in LLM Application Development</a></li>
  </ul></li>
  <li><a href="#break" id="toc-break" class="nav-link" data-scroll-target="#break">Break</a>
  <ul class="collapse">
  <li><a href="#quick-recap" id="toc-quick-recap" class="nav-link" data-scroll-target="#quick-recap">Quick Recap</a></li>
  <li><a href="#key-applications-recognized" id="toc-key-applications-recognized" class="nav-link" data-scroll-target="#key-applications-recognized">Key Applications Recognized</a></li>
  <li><a href="#limitations-and-ethical-considerations-of-large-language-models" id="toc-limitations-and-ethical-considerations-of-large-language-models" class="nav-link" data-scroll-target="#limitations-and-ethical-considerations-of-large-language-models">Limitations and Ethical Considerations of Large Language Models</a></li>
  <li><a href="#is-this-hallucination-llama2-13b-from-meta" id="toc-is-this-hallucination-llama2-13b-from-meta" class="nav-link" data-scroll-target="#is-this-hallucination-llama2-13b-from-meta">Is this Hallucination? (llama2-13b from Meta)</a></li>
  <li><a href="#is-this-hallucination-llama2-7b-from-meta" id="toc-is-this-hallucination-llama2-7b-from-meta" class="nav-link" data-scroll-target="#is-this-hallucination-llama2-7b-from-meta">Is this Hallucination? (llama2-7b from Meta)</a></li>
  <li><a href="#how-does-grounding-work" id="toc-how-does-grounding-work" class="nav-link" data-scroll-target="#how-does-grounding-work">How does ‘Grounding’ work?</a></li>
  <li><a href="#why-doesnt-grounding-work" id="toc-why-doesnt-grounding-work" class="nav-link" data-scroll-target="#why-doesnt-grounding-work">Why doesn’t ‘Grounding’ work?</a>
  <ul class="collapse">
  <li><a href="#grounding-may-improve-verifiability-of-a-models-response-it-wont-eliminate-the-issue." id="toc-grounding-may-improve-verifiability-of-a-models-response-it-wont-eliminate-the-issue." class="nav-link" data-scroll-target="#grounding-may-improve-verifiability-of-a-models-response-it-wont-eliminate-the-issue."><strong>‘Grounding’ may improve verifiability of a model’s response, it won’t eliminate the issue.</strong></a></li>
  </ul></li>
  <li><a href="#mitigating-llm-risks" id="toc-mitigating-llm-risks" class="nav-link" data-scroll-target="#mitigating-llm-risks">Mitigating LLM Risks</a></li>
  <li><a href="#quick-re-cap-on-what-we-discussed" id="toc-quick-re-cap-on-what-we-discussed" class="nav-link" data-scroll-target="#quick-re-cap-on-what-we-discussed">Quick Re-Cap on what we discussed</a></li>
  <li><a href="#quick-re-cap-on-what-we-discussed---synthesized" id="toc-quick-re-cap-on-what-we-discussed---synthesized" class="nav-link" data-scroll-target="#quick-re-cap-on-what-we-discussed---synthesized">Quick Re-Cap on what we discussed - Synthesized</a></li>
  <li><a href="#some-options-to-testunderstand-llms" id="toc-some-options-to-testunderstand-llms" class="nav-link" data-scroll-target="#some-options-to-testunderstand-llms">Some Options to test/understand LLMs</a></li>
  <li><a href="#some-options-to-testunderstand-llms-1" id="toc-some-options-to-testunderstand-llms-1" class="nav-link" data-scroll-target="#some-options-to-testunderstand-llms-1">Some Options to test/understand LLMs</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">DESN9002: Sustainable Leadership</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="desn9002-sustainable-leadership" class="level3">
<h3 class="anchored" data-anchor-id="desn9002-sustainable-leadership">DESN9002: Sustainable Leadership</h3>
<p>Welcome, and let’s start with some house-keeping items.</p>
<div style="color: lightgrey; text-align: left; margin-bottom: 20px;font-size: 25pt">
<pre><code>What is this course about?</code></pre>
</div>
<div style="text-align: center; font-weight: bold; font-size: 25pt">
<pre><code>Learn about Sustainability,&lt;br&gt;
Observe, Experience and Practice Leadership.</code></pre>
</div>
<div style="color: lightgrey; text-align: left; margin-bottom: 20px;font-size: 25pt">
<pre><code>Who to work with</code></pre>
</div>
<div style="text-align: left;">
<pre><code>▶  &lt;strong/&gt;Instructor:&lt;/strong&gt; Dr. Hongshan Guo &lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- Lectures, Sustainability, Time Series (Predictive Analytics), Prototyping, Project/Idea scoping &lt;br&gt;
▶ &lt;strong/&gt;Teaching Assistants&lt;/strong&gt; &lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- Brad: Ice-breaking, presentation, project management, team formation &lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- Abel: Logistics, announcements, social science, stats in general &lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- Hsiang: Design, visualization, UI/UX design &lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;- Ishawn (Hackathon only): General Programming, LLMs &amp; App-Building &lt;br&gt;
▶ &lt;strong/&gt;Guest Speakers:&lt;/strong&gt; External, TBC</code></pre>
</div>
<div id="d96e659a" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install qrcode</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Collecting qrcode
  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.2/46.2 kB 140.0 kB/s eta 0:00:00a 0:00:01
Collecting pypng
  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.1/58.1 kB 415.3 kB/s eta 0:00:00a 0:00:01
Requirement already satisfied: typing-extensions in /Users/hongshanguo/anaconda3/lib/python3.10/site-packages (from qrcode) (4.5.0)
Installing collected packages: pypng, qrcode
Successfully installed pypng-0.20220715.0 qrcode-7.4.2</code></pre>
</div>
</div>
<div id="117c4c30" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> qrcode</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="77e00338" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>slackchannel<span class="op">=</span>qrcode.make(<span class="st">'https://tinyurl.com/desn9002'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="58c96253" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>survey <span class="op">=</span>qrcode.make(<span class="st">'http://etc.ch/sZVF'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div style="color: lightgrey; text-align: left; margin-bottom: 20px;font-size: 25pt">
<pre><code>How to work together</code></pre>
</div>
<div style="text-align: left;">
<ul>
<li>Course Announcements &amp; Assignment Submissions: Moodle<br></li>
<li><strong>IM Platform</strong>: Slack<br> https://tinyurl.com/desn9002</li>
</ul>
</div>
<div id="da7fe4ff" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;fragment&quot;}" data-execution_count="32">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>slackchannel</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<div>
<figure class="figure">
<p><img src="LLMNotes_L1_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div>
<ul>
<li><strong>&gt;Remote Options</strong>: Teams/Outlook<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- ping TAs if invites don’t show up on your outlook calendars.<br></li>
</ul>
</div>
<div style="color: lightgrey; text-align: left; margin-bottom: 20px; font-size:25pt">
<pre><code>How are you graded</code></pre>
</div>
<div style="text-align: center;">
<pre><code>&lt;strong/&gt; Essays, Group Project (Hackathon) Critique and Peer-evaluation&lt;/strong&gt;&lt;br&gt;
&lt;/div&gt;</code></pre>
<div style="text-align: left; ">
<ul>
<li>Essays reflecting on guest lectures, use your own experience (chatGPT?)<br></li>
<li>Group Project aka Hackathon Output: Peer-grading (50%) + Instructor grading (50%)<br></li>
<li>Peer-evaluation: Group contribution agreed and recognized within each group.<br></li>
</ul>
</div>
<div style="color: lightgrey; text-align: left; margin-bottom: 20px; font-size:25pt">
<pre><code>Group Project/Hackathon</code></pre>
</div>
<div style="text-align: center;">
<pre><code>&lt;strong/&gt; Early detection of humanitarian crisis through multi-platform monitoring of multi-(social)media information.&lt;/strong&gt;&lt;br&gt;
&lt;/div&gt;</code></pre>
<div style="text-align: left; ">
<ol type="1">
<li>Form Groups (each group should have representative of all majors), i.e.&nbsp;group size ≤ 5<br></li>
<li>Programmers, designers and researchers - but what about PMs?<br></li>
<li>Hackathon is time-boxed but research can start <strong>now</strong>.<br></li>
</ol>
</div>
<div id="34f831c8" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;skip&quot;}" data-execution_count="22">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>qrsurvey<span class="op">=</span> Image(filename<span class="op">=</span> <span class="st">"../QRPoll.png"</span>,width<span class="op">=</span><span class="dv">400</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div style="color: lightgrey; text-align: left; margin-bottom: 20px;font-size: 25pt">
<pre><code>Let's kick-off with a small survey</code></pre>
</div>
<div id="76556f82" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;fragment&quot;}" data-execution_count="31">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>survey</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<div>
<figure class="figure">
<p><img src="LLMNotes_L1_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div style="text-align: center; font-size: 35pt;margin-bottom: 130pt; font-weight: bold">
Introduction to LLMs: What they are, why they’re powerful, why do we need to know about them
</div>
<div style="text-align: center;">
Hongshan Guo<br> September 22, 2023
</div>
</div></div></section>
<section id="what-do-you-already-know-about-llmschatgpt" class="level2">
<h2 class="anchored" data-anchor-id="what-do-you-already-know-about-llmschatgpt">What do you already know about LLMs/chatGPT?</h2>
<p>tldr version?</p>
<ul>
<li>Language model trained on large text corpus,</li>
<li>somehow capable of generating text sequence</li>
<li>Tech industry/stock market went crazy, for a while</li>
<li>Hallucination - what does it mean? Let’s have a look at an example for non-hallucination first.</li>
</ul>
<section id="prerequisite" class="level3">
<h3 class="anchored" data-anchor-id="prerequisite">PreRequisite</h3>
<p>Temperature-checking - how many of these concepts are we not familiar with? 1. Introduction to Machine Learning: ML, Supervised/Unsupervised; 2. Deep Learning (Basics): Neural networks, activation functions, backpropagation, gradient desent; 3. Convolutional Neural Networks: CNN &amp; application in CV tasks; 4. Recurrent Neural Networks (RNNs): Basics, LSTM and GRU &amp; usage in sequence data; 5. Intro to NLP: Overview of NLP - tokenization, word embeddings, sentiment analysis; 6. Seq2Seq models: how they work and their role in tasks like machine translation; 7. Attention Mechanism: Attention, Significance in transforming sequences; 8. Transformers and BERT</p>
</section>
<section id="lecture-overview" class="level3">
<h3 class="anchored" data-anchor-id="lecture-overview">Lecture Overview</h3>
<ol type="1">
<li><p><strong>Introduction to LLMs</strong>: What LLMs are and why they’re important</p></li>
<li><p><strong>Training LLMs</strong>: On LLM’s training including challenges and techniques involved</p></li>
<li><p><strong>Understanding GPT Architecture</strong>: Understand GPT architecture used in LLMs.</p></li>
<li><p><strong>Fine-tuning Large Language Models</strong>: Concept of fine-tuning and its application in LLMs.</p></li>
<li><p><strong>Applications of LLMs</strong>: Examine real-world applications of LLMs within various use cases.</p></li>
<li><p><strong>Evaluating LLMs</strong>: Learn about different metrics and methods and their <em>caveats</em> to evaluate the performance of LLMs.</p></li>
<li><p><strong>Bias in LLMs</strong>: Discuss the potential for bias in LLMs and how to mitigate it.</p></li>
<li><p><strong>Limitations and Future of LLMs</strong>: Discuss the current limitations of LLMs and future research directions.</p></li>
<li><p><strong>Hackathon-related refreshers</strong>: Stochastics of time seires, API-based call of LLMs and Graphical Programming Interface that requires little-to-zero coding</p></li>
</ol>
</section>
<section id="introduction-to-llms-and-how-they-are-trained" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-llms-and-how-they-are-trained">Introduction to LLMs and how they are trained</h3>
<p>A type of ML model designed to understand, generate and converse in human language, ‘large’ due to the vast number of parameters. - Ability to generate human-like texts - Patterns in data used to train the model learnt allows the models to generate text based on received inputs - Rule of thumb: 7B parameters takes one sota GPU to run, i.e.&nbsp;13B takes two, etc. - LLMs can perform natural language processing (NLP) tasks, note LLM ≠ NLP model - OpenAI first released GPT-1 in 2018, and GPT 3 in 2020, where terrabytes of data were used to train these models</p>
</section>
<section id="lets-see-some-llms-in-action" class="level3">
<h3 class="anchored" data-anchor-id="lets-see-some-llms-in-action">Let’s see some LLMs in action</h3>
</section>
<section id="architecture-of-llm" class="level3">
<h3 class="anchored" data-anchor-id="architecture-of-llm">Architecture of LLM</h3>
<p>‘Attention is All you Need’, seminal paper on the most commonly used architecture known as <strong>transformer</strong> was first proposed, revoluntionized the field of NLP. - Transformers are based on the <strong>attention</strong> mechanism, which allows the model to better associate words w.r.t. their positions, of primarily two types: - self-attention - multi-head attention - Transformer = <strong>encoder</strong> (input) + <strong>decoder</strong> (Output)</p>
<div id="ac99ef3b" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;subslide&quot;}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>transformerarch</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#For those more keen on looking at the two components - note that GPT-3 is decoder only</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<img src="https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png" width="400">
</div>
</div>
</section>
<section id="architecture-of-llm---transformer-layer-types" class="level3">
<h3 class="anchored" data-anchor-id="architecture-of-llm---transformer-layer-types">Architecture of LLM - Transformer Layer Types</h3>
<ol type="1">
<li>Self-Attention Layer: Scaled Dot-Product Attention
<ul>
<li>Allows model to focus on different parts of the input sequence when producing an output.
<ul>
<li>e.g.&nbsp;“The cat, which already ate…., was full.” can prioritize “The cat” with “was full” before “already ate”;</li>
</ul></li>
</ul></li>
<li>Position-wise Feed-Forward Layer
<ul>
<li>Fully-connected feed-forward network that is applied to each position separately and identically, each consists two linear transformations with a ReLU activation in between;</li>
<li>Used to sequentially process the output of the self-attention layer, appying the same learnt weights at every position;</li>
</ul></li>
<li>Output layer
<ul>
<li>Linear layer followed by a softmax function, transforms the final hidden states to predictions for the next word in the sequence for each possible word in the vocabulary.</li>
</ul></li>
</ol>
</section>
<section id="architecture-of-llm---data-handling-by-gpt-models" class="level3">
<h3 class="anchored" data-anchor-id="architecture-of-llm---data-handling-by-gpt-models">Architecture of LLM - Data Handling by GPT Models</h3>
<section id="tokenization" class="level4">
<h4 class="anchored" data-anchor-id="tokenization">Tokenization</h4>
<p>Process of converting sequence of text into a sequence of tokens - a (part of) word. <em>Byte Pair Encoding</em> platform.openai.com/tokenizer</p>
<p>https://chatgpt.hku.hk is now available thanks to Prof.&nbsp;Ian Holiday. 50K tokens per month - do you know what tokens are?</p>
</section>
<section id="bpe" class="level4">
<h4 class="anchored" data-anchor-id="bpe">BPE</h4>
<ul>
<li>subwod tokenization method,
<ul>
<li>starts by splitting text into individual characters and</li>
<li>iteratively merges the most frequently adjacent pair of symbols.</li>
</ul></li>
<li>helps handle out-of-vocabulary words and makes the model more robust to spelling errors and variations</li>
</ul>
</section>
<section id="sequence-length" class="level4">
<h4 class="anchored" data-anchor-id="sequence-length">Sequence length</h4>
<ul>
<li>context window size (2048 for GPT-3, 8K for GPT-4 or 32K)</li>
<li>Limit on the number of tokens they can be passed at once due to memory constraints</li>
<li>For an decoder-only model takes the input sequence all at once, where each token and its relationships with every other token in the sequence in memory</li>
<li>quadratic increase in memory usage at the sequence length grows</li>
<li>Primarily to make the model feasible to run on available hardware</li>
<li><strong>Longer (input + output) sequence takes very long to generate</strong></li>
</ul>
</section>
</section>
<section id="architecture-of-llm---implementation-and-deployment-of-gpt" class="level3">
<h3 class="anchored" data-anchor-id="architecture-of-llm---implementation-and-deployment-of-gpt">Architecture of LLM - Implementation and deployment of GPT</h3>
<section id="implementation" class="level4">
<h4 class="anchored" data-anchor-id="implementation">Implementation</h4>
<ul>
<li>Unlikely going to have retraining schedules.</li>
<li>May require initial fine-tuning or tweaking OR</li>
<li>Vanilla</li>
<li>GPT-in-general: Implemented with Tensorflow or PyTorch: efficient, GPU-accelerated operations</li>
</ul>
</section>
<section id="deployment-process" class="level4">
<h4 class="anchored" data-anchor-id="deployment-process">Deployment Process</h4>
<ul>
<li>Models needs to reside on robust hardware or cloud-based solutions: consider numerous simultaneous requests</li>
<li>Typically involves API-calls made to request services from models deployed on network</li>
<li>Requests (e.g.&nbsp;text generation, text-completion) are handled and responses sent back</li>
</ul>
</section>
</section>
<section id="architecture-of-llm---back-to-the-sota-models" class="level3">
<h3 class="anchored" data-anchor-id="architecture-of-llm---back-to-the-sota-models">Architecture of LLM - Back to the SOTA models</h3>
<p>GPT-3, GPT-J, etc.: An <strong>autoregressive, decoder-only transformer model</strong> designed to solve natural language processing (NLP) tasks by <strong>predicting</strong> how a piece of text will continue.</p>
<p>This is different from traditional encoder-decoder transformer models like BERT where the inputs are first encoded and thrown together at the model as a whole when making the prediction.</p>
<p>GPT-3-like decoder-only models puts more emphasis on the more recent inputs, maknig the prediction continuously being more relevant with the more recent information.</p>
<ul>
<li>Advantage of decoder-only architecture:
<ul>
<li>Simplicity: easier to train less computationally expensive</li>
<li>Good at generative tasks, producing contextually relevant text - model is built to generate output one token at a time;</li>
</ul></li>
<li>Advantage of encoder-decoder model:
<ul>
<li>Better at classification tasks - tasks where specific structure is needed, e.g.&nbsp;translation, summarization, particularly good when input information comes all at once</li>
</ul></li>
</ul>
<p>Note here these are just high-level benefits, YMMV with different use cases.</p>
<p>A few notes:</p>
<ol type="1">
<li><em>Autoregressiveness equals no parallelized during inference</em></li>
<li><em>Autoencoder</em> models should be differentiated from encoder-decoder model:
<ul>
<li>the prior also has an encoder and a decoder but primarily serves the purpose of dimension-reduction and denoising, aka ‘learning’ the input while</li>
<li>the latter is designed to work in sequence-to-sequence tasks.</li>
<li>i.e.&nbsp;autoencoder’s output is representation of its input</li>
<li>encoder-decoder is not just a reconstruction of the input</li>
</ul></li>
</ol>
<p>Tying this back to GPT-3 models (and its alikes): LLMs performs sequence-to-sequence tasks but puts more weights to more recent context, yet it still considers all previous tokens (history) to predict the upcoming token.</p>
</section>
<section id="architecture-of-llm---generative-pre-trained-transformer-aka-openais-proposal" class="level3">
<h3 class="anchored" data-anchor-id="architecture-of-llm---generative-pre-trained-transformer-aka-openais-proposal">Architecture of LLM - Generative Pre-trained Transformer aka OpenAI’s proposal</h3>
<ol type="1">
<li>GPT-1: Improving Language Understanding by Generative Pre-training” in June 2018. 12 transformer layers and 117m parameters;</li>
<li>GPT-2: Released in 2019, has 1.5B parameters, text can become indistinguiashable to text written by humans;</li>
<li>GPT-3: Launched in 2020, (disclosed) largeset variant at 175B parameters, generate coherent and contextually relevant passages of text, introduction of ‘few-shot learning’.
<ul>
<li>translation</li>
<li>Q&amp;A</li>
<li>Writing creative contents like poems and stories</li>
</ul></li>
<li>GPT-4: Released in 2023, no. of parameter undisclosed, still known as the most powerful LLM that has been released;</li>
</ol>
<p>GPT-3.5: sub-class of GPT-3 first released in Apr.&nbsp;2022, leading to ‘<strong>chatGPT</strong>’ in Nov.&nbsp;2023.</p>
</section>
<section id="applications-of-llms-examine-real-world-applications-of-llms-within-various-use-cases." class="level3">
<h3 class="anchored" data-anchor-id="applications-of-llms-examine-real-world-applications-of-llms-within-various-use-cases.">Applications of LLMs: Examine real-world applications of LLMs within various use cases.</h3>
<ul>
<li>Chatbots: User intention and logic. Short back-and-forth limits the need for larger context window</li>
<li>Script-writing: Hollywood writers still on strike - although for a different reason now.</li>
</ul>
<p>Evaluating LLMs: Learn about different metrics and methods and their caveats to evaluate the performance of LLMs. Bias in LLMs: Discuss the potential for bias in LLMs and how to mitigate it. Limitations and Future of LLMs: Discuss the current limitations of LLMs and future research directions. Hackathon-related refreshers: Stochastics of time seires, API-based call of LLMs and Graphical Programming Interface that requires little-to-zero coding</p>
</section>
<section id="common-selection-strategies-seen-in-llm-application-development" class="level3">
<h3 class="anchored" data-anchor-id="common-selection-strategies-seen-in-llm-application-development">Common Selection Strategies seen in LLM Application Development</h3>
<p>Inference-time paramters that affect how tokens are generated by a LLM. - Temperature: Deterministic to Creativity - Randomness of model output (0-1) - When set to 0, outputs is completely reproducible - When set to 1, model is more random, aka has more ‘creative’ outputs - Top_K Sampling: Number of top tokens considered for best next word - limits us to a certain number of the top tokens to consider</p>
<ul>
<li>Top_P Sampling: Probability threshold
<ul>
<li>Recall the models are statistical in nature, use a threashold of probability, e.g.&nbsp;90%</li>
</ul></li>
<li>Token length &amp; Max tokens: Number of tokens fed to/generated by LLMs
<ul>
<li>Relevant due to the amount of time of solution generated</li>
<li>Also relevant to costs (Most close models charge by # of tokens used)</li>
</ul></li>
</ul>
</section>
</section>
<section id="break" class="level1">
<h1>Break</h1>
<section id="quick-recap" class="level2">
<h2 class="anchored" data-anchor-id="quick-recap">Quick Recap</h2>
<ul>
<li>Talked about onboarding to GCP and some high-level contents w.r.t. how LLMs work</li>
<li>In particular touch upon the following concept:
<ul>
<li>Temperature</li>
<li>top_N</li>
<li>probabilities</li>
</ul></li>
<li>Now switching gear back to the learning series, we will talk about Application of LLMs today.</li>
<li>Let’s begin with the five common pillars recognized by OpenAI (or GPT-4 itself)</li>
</ul>
</section>
<section id="key-applications-recognized" class="level2">
<h2 class="anchored" data-anchor-id="key-applications-recognized">Key Applications Recognized</h2>
<ol type="1">
<li>Content Creation
<ul>
<li>write articles</li>
<li>generate ideas/scripts for writers</li>
<li><strong>creativity and fluency</strong></li>
</ul></li>
<li>Conversation Agents:
<ul>
<li>chatbot/virtual assistant (Pershin X)</li>
<li>Human-like <strong>interaction</strong></li>
<li><em>Can answer queries, provide recommendations and hold conversations</em></li>
</ul></li>
<li>Translation:
<ul>
<li>not explicitly trained to do this</li>
<li><em>Can handle various languages nonetheless</em></li>
</ul></li>
<li>Education
<ul>
<li>Tutor various subjects</li>
<li><em>Can provide explanations, stimulate creative thinking</em></li>
</ul></li>
<li>Programming Help: CoPilot
<ul>
<li><em>Can generate code snippets and assist with debugging</em></li>
</ul></li>
</ol>
</section>
<section id="limitations-and-ethical-considerations-of-large-language-models" class="level2">
<h2 class="anchored" data-anchor-id="limitations-and-ethical-considerations-of-large-language-models">Limitations and Ethical Considerations of Large Language Models</h2>
<ul>
<li>Limitations
<ul>
<li>Understanding vs.&nbsp;Pattern Matching</li>
<li>Sensitivity to Input Phrasing</li>
<li>Verifiability of information: generating plausible-sounding but incorrect/nonsensical information.
<ul>
<li>no inherent way to verify accuracy of the information it generates</li>
<li><strong>but doesn’t ‘grounding’ solve this?</strong></li>
</ul></li>
</ul></li>
<li>Ethical Considerations
<ul>
<li>Bias in Training Data
<ul>
<li>gender, racial cultral biases and more</li>
</ul></li>
<li>Misuse of Technology
<ul>
<li>deepfake text for nefarious purposes</li>
</ul></li>
<li>Social/Environmental Impact
<ul>
<li>training of LLM is very energy intensive ad requires significant amount of computational resources</li>
<li>Role of human/smart copiers’ role in RLHF</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="is-this-hallucination-llama2-13b-from-meta" class="level2">
<h2 class="anchored" data-anchor-id="is-this-hallucination-llama2-13b-from-meta">Is this Hallucination? (llama2-13b from Meta)</h2>
<ul>
<li><span style="color:blue; font-weight:bold">Q</span>: When did Mickey Mouse die?</li>
<li><span style="color:red; font-weight:bold">A1</span>: Mickey Mouse, the iconic cartoon character created by Walt Disney and Ub Iwerks in the 1920s, has not died. He is a fictional character and has been featured in countless animated films, television shows, comics, and other forms of media. Therefore, he has never actually died. However, if you’re asking about the character’s where- abouts or activities, it’s important to note that Mickey Mouse is a fictional character and does not have a physi- cal presence or real-world experiences. He exists solely as a cartoon character and is not capable of dying or experienc- ing death in the same way that real people do. (llama2- 13b)</li>
</ul>
</section>
<section id="is-this-hallucination-llama2-7b-from-meta" class="level2">
<h2 class="anchored" data-anchor-id="is-this-hallucination-llama2-7b-from-meta">Is this Hallucination? (llama2-7b from Meta)</h2>
<ul>
<li><span style="color:blue; font-weight:bold">Q</span>: When did Mickey Mouse die?</li>
<li><span style="color:red; font-weight:bold">A2</span>: Mickey Mouse, the beloved cartoon character created by Walt Disney and Ub Iwerks in 1928, is not a real per- son and has not died. Unterscheidung von Mickey Mouse und realen Menschen. Mickey Mouse is an fictional char- acter and has never been alive, so he has not died. He was created as a cartoon character for the Disney Broth- ers Cartoon Studio, which later became The Walt Disney Company, and has been a beloved character around the world for generations. (llama2-7b)</li>
</ul>
<p>The decoder-only transformer models are <strong>autoregressive</strong> in nature, i.e.&nbsp;they use the given context to predict words that are most likely going to occur according to the relationship they’ve already ’learnt’.</p>
</section>
<section id="how-does-grounding-work" class="level2">
<h2 class="anchored" data-anchor-id="how-does-grounding-work">How does ‘Grounding’ work?</h2>
<ul>
<li><p>What is ‘grounding’:</p>
<ul>
<li>Refers to the concept of connecting the LLM with real-world concrete data or knowledge source</li>
<li>May include:
<ul>
<li>linking to specific databases,</li>
<li>using factual knowledge graphs, or</li>
<li>providing the model with access to up-to-date information on the internet.</li>
</ul></li>
</ul></li>
<li><p>MSFT once claimed it will resolve most of our concerns/problems.</p></li>
<li><p><strong>Verfiability issue is more than just factual grounding.</strong></p></li>
</ul>
</section>
<section id="why-doesnt-grounding-work" class="level2">
<h2 class="anchored" data-anchor-id="why-doesnt-grounding-work">Why doesn’t ‘Grounding’ work?</h2>
<ul>
<li>Grouding will improve accuracy of responses and keep them factual</li>
<li>Creates a form of question-answering system that performs semantic search over a known corpus of documents</li>
<li>Some points to consider:
<ol type="1">
<li>Model interpretation (temp=0, aka model outputs more deterministic): model understanding ≠ human understanding;</li>
<li>Accuracy within context: errors acn arise from:
<ul>
<li>biases/inaccuracies in training data,</li>
<li>misinterpretation of context,</li>
<li>limitations in the model’s understanding of complex language structures;</li>
</ul></li>
<li>Handling Ambiguity: question or context is ambigous, the model might struggle to provide an accurate and relevant answer.</li>
</ol></li>
</ul>
<section id="grounding-may-improve-verifiability-of-a-models-response-it-wont-eliminate-the-issue." class="level3">
<h3 class="anchored" data-anchor-id="grounding-may-improve-verifiability-of-a-models-response-it-wont-eliminate-the-issue."><strong>‘Grounding’ may improve verifiability of a model’s response, it won’t eliminate the issue.</strong></h3>
</section>
</section>
<section id="mitigating-llm-risks" class="level2">
<h2 class="anchored" data-anchor-id="mitigating-llm-risks">Mitigating LLM Risks</h2>
<ul>
<li>Fine-tuning on specific datasets: improve behavior for <strong>specific</strong> applications
<ul>
<li>Refers to the concept of connecting the LLM with real-world concrete data or knowledge source</li>
<li>May include:
<ul>
<li>linking to specific databases,</li>
<li>using factual knowledge graphs, or</li>
<li>providing the model with access to up-to-date information on the internet.</li>
</ul></li>
</ul></li>
<li><strong>Verfiability issue is more than just factual grounding.</strong></li>
</ul>
</section>
<section id="quick-re-cap-on-what-we-discussed" class="level2">
<h2 class="anchored" data-anchor-id="quick-re-cap-on-what-we-discussed">Quick Re-Cap on what we discussed</h2>
<ul>
<li>Basics of LLMs
<ul>
<li>What they are and how they are trained</li>
</ul></li>
<li>Architecture of GPT models (Decoder-only ones started by OpenAI)
<ul>
<li>Transformer architecture</li>
<li>Decoder-only vs.&nbsp;encoder-decoder architectures</li>
</ul></li>
<li>Implementation and Deployment
<ul>
<li>APIs</li>
<li>Real-world usage and applications we built</li>
</ul></li>
<li>Limitations and Concerns
<ul>
<li>Lack of human-intent-understanding capability</li>
<li>Inability to provide verification</li>
<li>Proneness to biases</li>
</ul></li>
<li>Implications of LLMs
<ul>
<li>Wide-ranging capabilities and applications of these models</li>
<li>Potential risks and concerns</li>
<li>Strategies to mitigate these risks</li>
</ul></li>
</ul>
</section>
<section id="quick-re-cap-on-what-we-discussed---synthesized" class="level2">
<h2 class="anchored" data-anchor-id="quick-re-cap-on-what-we-discussed---synthesized">Quick Re-Cap on what we discussed - Synthesized</h2>
<ul>
<li>Basics of LLMs
<ul>
<li>Generative Pre-Trained (on large text corpora) Models</li>
</ul></li>
<li>Architecture of GPT models (Decoder-only ones started by OpenAI)
<ul>
<li>Decoder-only, no parallization</li>
</ul></li>
<li>Implementation and Deployment
<ul>
<li>OpenAI &amp; Google: APIs</li>
<li>Open-Source models: Google Colab, i.e.&nbsp;local/remote GPUs(CLI)</li>
</ul></li>
<li>Limitations and Concerns
<ul>
<li>It doesn’t ‘understand’ prompts and human intentions</li>
<li>But can sound very convincing as trained on great writing examples - is it a better writer?</li>
</ul></li>
<li>Implications of LLMs
<ul>
<li>Different learning experiences</li>
<li>Revolutionize coding experience (CoPilot)</li>
<li>Further reduction of workforce (e.g.&nbsp;Customer Service, call center reps)</li>
</ul></li>
</ul>
</section>
<section id="some-options-to-testunderstand-llms" class="level2">
<h2 class="anchored" data-anchor-id="some-options-to-testunderstand-llms">Some Options to test/understand LLMs</h2>
<ul>
<li>Langflow: Python implementation <img src="https://raw.githubusercontent.com/logspace-ai/langflow/main/img/langflow-demo.gif" class="img-fluid" alt="Workflow of Langflow"></li>
</ul>
</section>
<section id="some-options-to-testunderstand-llms-1" class="level2">
<h2 class="anchored" data-anchor-id="some-options-to-testunderstand-llms-1">Some Options to test/understand LLMs</h2>
<ul>
<li>Flowise: Node.js Implementation <img src="https://1778525056-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2Fy8ifwt9BYklr92KDdr48%2Fuploads%2FmY3QYdGqSbYS4fQJ8eOc%2Fflowise.gif?alt=media&amp;token=327aa9cd-7432-40d8-8073-cc82d7ef9fc9" class="img-fluid" alt="Workflow of Flowise"></li>
</ul>
<div id="7bededcb" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;skip&quot;}" data-execution_count="33">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud, STOPWORDS</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_word_cloud(text):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a set of stopwords</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    stopwords <span class="op">=</span> <span class="bu">set</span>(STOPWORDS)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate a word cloud</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    wordcloud <span class="op">=</span> WordCloud(width<span class="op">=</span><span class="dv">2500</span>, height<span class="op">=</span><span class="dv">500</span>, </span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>                          background_color<span class="op">=</span><span class="st">'white'</span>, </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>                          stopwords<span class="op">=</span>stopwords, </span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                          min_font_size<span class="op">=</span><span class="dv">8</span>).generate(text)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the WordCloud image</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>), facecolor<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    plt.imshow(wordcloud)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout(pad<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>